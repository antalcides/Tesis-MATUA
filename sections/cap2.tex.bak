


\chapter{Diseños \'optimos en la presencia de efectos de bloques aleatorios}
%recuperar numeracion arabica%
\def\thechapter{\arabic{chapter}}
\lettrine[lines=4,loversize=-0.1,lraise=0.1,lhang=.2]{P}{ara un modelo lineal en la presencia de efectos de bloques aleatorios se describe la situaci\'on donde se tienen $b$ bloques, cada uno con $m_{i}$ observaciones. Por lo tanto,} la $j$-\'esima observaci\'on $Y_{ij}$ al bloque $i$ se puede escribir como\\
\begin{equation}
Y_{ij} =\gamma_{i} + \beta_{0} + \mathbf{f}(\mathrm{x}_{ij})^{\top}\boldsymbol{\beta} + \epsilon_{ij}
\end{equation}
\\
donde $\mathrm{x}_{ij}$ son los puntos experimentales, $j=1,...,m_{i}$, $\boldsymbol{f}=(f_{1},...,f_{p})^{\top}$ es un conjunto de funciones (conocidas) de regresi\'on y $\beta_{0}\in\mathbb{R}$, $\boldsymbol{\beta}=(\beta_{1},...,\beta_{p})^{\top}$  son los par\'ametros desconocidos. $f$ puede ser la funci\'on identidad para regresi\'on lineal simple.\\

El término $\gamma_{i}$ es el efecto del $i$-\'esimo bloque aleatorio con $E(\gamma_{i})=0$ y $Var(\gamma_{i} )=\sigma_{\gamma}^{2}$. Los errores de observaci\'on aleatorio $\epsilon_{ij}$ se supone que son homoscedasticos, $E(\epsilon_{ij} )=0$, $Var(\epsilon_{ij})=\sigma^{2}$ y $Cov(\gamma_{i},\epsilon_{ij})=0$. El an\'alisis adicional depender\'a del cociente de varianza $d=\sigma_\gamma^{2} / \sigma^{2}$ . Nos centraremos en los par\'ametros de la poblaci\'on $\theta=(\beta_{0},\boldsymbol{\beta}^{\top})^{\top}$. Asumiremos que el n\'umero de observaciones por bloque es constante, es decir, $m_{i}=m$.\\

Denotemos por $\boldsymbol{Y}_{i}=(Y_{i1},...,Y_{im})^{\top}$  el vector de observaciones para el bloque $i$. La matriz de covarianza correspondiente $Cov(\boldsymbol{Y}_{i})=\sigma^{2}\boldsymbol{V}$ es completamente sim\'etrica, $\boldsymbol{V}=\boldsymbol{I}_{m}+d\boldsymbol{1}_{m}\boldsymbol{1}_{m}^{\top}$, donde $\boldsymbol{I}_{m}$ indica la matriz identidad $m \times m$ y $\boldsymbol{1}_{m}$ es un vector de longitud $m$ con todas las entradas iguales a uno. El efecto fijo individual de la matriz de diseño $\boldsymbol{X}_{i}=(\boldsymbol{1}_{m}\mid \boldsymbol{F}_{i})$ se puede descomponer en la primera columna de unos correspondiente a la intersección $\beta_{0}$ y la matriz de diseño para el vector de par\'ametros $\boldsymbol{\beta}$.\\ 

La inversa de $\boldsymbol{V}$ la podemos hallar mediante \'algebra matricial\
\begin{equation}
\begin{aligned}
\boldsymbol{V}^{-1} & = (\boldsymbol{I}_{m} + d\boldsymbol{1}_{m}\boldsymbol{1}_{m}^{\top})^{-1}\\
& = \boldsymbol{I} - d^{\frac{1}{2}}\boldsymbol{1}_{m}(\boldsymbol{I} + d\boldsymbol{1}_{m}^{\top}\boldsymbol{I}\boldsymbol{1}_{m})^{-1}d^{\frac{1}{2}}\boldsymbol{1}_{m}^{\top}\\
& = \boldsymbol{I} - d\boldsymbol{1}_{m}(\boldsymbol{I} + dm\boldsymbol{I})^{-1}\boldsymbol{1}_{m}^{\top}\\
& = \boldsymbol{I} - d\boldsymbol{1}_{m}(\boldsymbol{I}(1 + dm))^{-1}\boldsymbol{1}_{m}^{\top}\\
& = \boldsymbol{I} - \frac{d}{1 + dm}\boldsymbol{1}_{m}\boldsymbol{1}_{m}^{\top}
\end{aligned}
\end{equation}\\

 Luego, la matriz de informaci\'on por bloque, utilizando $(2\ldotp2)$ queda $\boldsymbol{X}_{i}^{\top}\boldsymbol{V}^{-1}\boldsymbol{X}_{i}=\boldsymbol{X}_{i}^{\top}\boldsymbol{X}_{i}-\frac{d}{1+md}\boldsymbol{X}_{i}^{\top}\boldsymbol{1}_{m}\boldsymbol{1}_{m}^{\top}\boldsymbol{X}_{i}$  que es proporcional a la inversa de la matriz de varianza-covarianza $Cov(\boldsymbol{\hat{\theta}}_{i})$ si $\boldsymbol{X}_{i}$ es de rango completo. As\'i $\boldsymbol{\theta}$ es estimado sobre una base por bloque
 
 \begin{equation}
 	\begin{aligned}
 	\nonumber
 		\boldsymbol{\hat{\theta}}_{i} & = (\boldsymbol{X}_{i}^{\top}\boldsymbol{V}^{-1}\boldsymbol{X}_{i})^{-1}\boldsymbol{X}_{i}^{\top}\boldsymbol{V}^{-1}\boldsymbol{Y}_{i}\\
 		\nonumber
  		& = (\boldsymbol{X}_{i}^{\top}\boldsymbol{X}_{i})^{-1}\boldsymbol{X}_{i}^{\top}\boldsymbol{Y}_{i}
 	\end{aligned}
 \end{equation}\\
 

 Sobre la base de la poblaci\'on el mejor estimador lineal insesgado se puede calcular como $\boldsymbol{\hat{\theta}}=\left(\displaystyle\sum_{i=1}^{b}\boldsymbol{X}_{i}^{\top}\boldsymbol{V}^{-1}\boldsymbol{X}_{i}\right)^{-1}\displaystyle\sum_{i=1}^{b}\boldsymbol{X}_{i}^{\top}\boldsymbol{V}^{-1}\boldsymbol{X}_{i}\boldsymbol{\hat{\theta}}_{i}$ si $d$ es conocido. Entonces $Cov(\boldsymbol{\hat{\theta}})=\sigma^{2}\boldsymbol{M}_{d}^{-1}$, donde $\boldsymbol{M}_{d}=\displaystyle\sum_{i=1}^{b}\boldsymbol{X}_{i}^{\top}\boldsymbol{V}^{-1}\boldsymbol{X}_{i}$ es la matriz de informaci\'on sobre la base de la poblaci\'on. El sub\'indice $d$ indica la dependencia del cociente de varianzas $d$. Como $\boldsymbol{M}_{d}=\displaystyle\sum_{i=1}^{b}\boldsymbol{X}_{i}^{\top}\boldsymbol{X}_{i}-\frac{d}{1+md}\displaystyle\sum_{i=1}^{b}\boldsymbol{X}_{i}^{\top}\boldsymbol{1}_{m}\boldsymbol{1}_{m}^{\top}\boldsymbol{X}_{i}$. \\\\
 
 La matriz de informaci\'on particionada de acuerdo a $\beta_{0}$ y $\boldsymbol{\beta}$, es
\\
\begin{equation}
\begin{aligned}
\nonumber
\boldsymbol{M}_{d} & = \displaystyle\sum_{i=1}^{b}\boldsymbol{X}_{i}^{\top}\boldsymbol{X}_{i}-\frac{d}{1+md}\displaystyle\sum_{i=1}^{b}\boldsymbol{X}_{i}^{\top}\boldsymbol{1}_{m}\boldsymbol{1}_{m}^{\top}\boldsymbol{X}_{i} \\\\
\nonumber
& = \displaystyle\sum_{i=1}^{b}(\boldsymbol{1}_{m}\mid \boldsymbol{F}_{i})^{\top}(\boldsymbol{1}_{m}\mid \boldsymbol{F}_{i})-\frac{d}{1+md}\displaystyle\sum_{i=1}^{b}(\boldsymbol{1}_{m}\mid \boldsymbol{F}_{i})^{\top}\boldsymbol{1}_{m}\boldsymbol{1}_{m}^{\top}(\boldsymbol{1}_{m}\mid \boldsymbol{F}_{i}) \\\\
\nonumber
& = \displaystyle\sum_{i=1}^{b}\begin{pmatrix}
\boldsymbol{1}_{m}^{\top} \\\\
\boldsymbol{F}_{i}^{\top} \\
\end{pmatrix}(\boldsymbol{1}_{m}\mid \boldsymbol{F}_{i})-\frac{d}{1+md}\displaystyle\sum_{i=1}^{b}\begin{pmatrix}
\boldsymbol{1}_{m}^{\top} \\\\
\boldsymbol{F}_{i}^{\top} \\
\end{pmatrix}\boldsymbol{1}_{m}\boldsymbol{1}_{m}^{\top}(\boldsymbol{1}_{m}\mid \boldsymbol{F}_{i}) \\\\
\nonumber
& = \displaystyle\sum_{i=1}^{b}\begin{pmatrix}
m & \boldsymbol{1}_{m}^{\top}\boldsymbol{F}_{i} \\\\
\boldsymbol{F}_{i}^{\top}\boldsymbol{1}_{m} & \boldsymbol{F}_{i}^{\top}\boldsymbol{F}_{i} \\
\end{pmatrix}-\frac{d}{1+md}\displaystyle\sum_{i=1}^{b}\begin{pmatrix}
m\\\\
\boldsymbol{F}_{i}^{\top}\boldsymbol{1}_{m} \\
\end{pmatrix}(m\mid \boldsymbol{1}_{m}^{\top}\boldsymbol{F}_{i}) \\\\
\nonumber
& = \displaystyle\sum_{i=1}^{b}\begin{pmatrix}
m & \boldsymbol{1}_{m}^{\top}\boldsymbol{F}_{i} \\\\
\boldsymbol{F}_{i}^{\top}\boldsymbol{1}_{m} & \boldsymbol{F}_{i}^{\top}\boldsymbol{F}_{i} \\
\end{pmatrix}-\frac{d}{1+md}\displaystyle\sum_{i=1}^{b}\begin{pmatrix}
m^{2} & m\boldsymbol{1}_{m}^{\top}\boldsymbol{F}_{i} \\\\
\boldsymbol{F}_{i}^{\top}\boldsymbol{1}_{m}m & \boldsymbol{F}_{i}^{\top}\boldsymbol{1}_{m}\boldsymbol{1}_{m}^{\top}\boldsymbol{F}_{i} \\
\end{pmatrix} \\\\
\nonumber
& = \frac{1}{1+md}\displaystyle\sum_{i=1}^{b}\begin{pmatrix}
m+m^{2}d & \boldsymbol{1}_{m}^{\top}\boldsymbol{F}_{i}+md\boldsymbol{1}_{m}^{\top}\boldsymbol{F}_{i} \\\\
\boldsymbol{F}_{i}^{\top}\boldsymbol{1}_{m}+md\boldsymbol{F}_{i}^{\top}\boldsymbol{1}_{m} & \boldsymbol{F}_{i}^{\top}\boldsymbol{F}_{i}+md\boldsymbol{F}_{i}^{\top}\boldsymbol{F}_{i} \\
\end{pmatrix} \\\\
\end{aligned}
\end{equation}
 $$-\frac{1}{1+md}\displaystyle\sum_{i=1}^{b}\begin{pmatrix}
 dm^{2} & dm\boldsymbol{1}_{m}^{\top}\boldsymbol{F}_{i} \\\\
 d\boldsymbol{F}_{i}^{\top}\boldsymbol{1}_{m}m & d\boldsymbol{F}_{i}^{\top}\boldsymbol{1}_{m}\boldsymbol{1}_{m}^{\top}\boldsymbol{F}_{i} \\
 \end{pmatrix}$$
 
 \begin{equation}
\boldsymbol{M}_{d}=\frac{1}{1+md}\left(\begin{tabular}{c | c}
$bm$ & $\displaystyle\sum_{i=1}^{b}\boldsymbol{1}_{m}^{T}\boldsymbol{F}_{i}$ \\
\hline
$\displaystyle\sum_{i=1}^{b}\boldsymbol{F}_{i}^{\top}\boldsymbol{1}_{m}$ & $(1+md)\displaystyle\sum_{i=1}^{b}\boldsymbol{F}_{i}^{\top}\boldsymbol{F}_{i}-d\displaystyle\sum_{i=1}^{b}\boldsymbol{F}_{i}^{\top}\boldsymbol{1}_{m}\boldsymbol{1}_{m}^{\top}\boldsymbol{F}_{i}$ \\
\end{tabular}\right)
 \end{equation} 
 \\
 \\
 
 Si el inter\'es est\'a en los efectos fijos $\boldsymbol{\beta}$ solamente, entonces las reglas para invertir las correspondientes matrices de informaci\'on parcial particionadas $\boldsymbol{M}_{\boldsymbol{\beta},d}^{-1}=Cov(\boldsymbol{\hat{\beta}})/\sigma^{2}$ es igual a\\
  \begin{equation}
  \boldsymbol{M}_{\boldsymbol{\beta},d}=\displaystyle\sum_{i=1}^{b}\boldsymbol{F}_{i}^{\top}\boldsymbol{F}_{i}-\frac{d}{1+md}\displaystyle\sum_{i=1}^{b}\boldsymbol{F}_{i}^{\top}\boldsymbol{1}_{m}\boldsymbol{1}_{m}^{\top}\boldsymbol{F}_{i}-\frac{1}{bm} \ \frac{1}{1+md}\left(  \displaystyle\sum_{i=1}^{b}\boldsymbol{F}_{i}^{\top}\boldsymbol{1}_{m}\right) \left( \displaystyle\sum_{i=1}^{b}\boldsymbol{1}_{m}^{\top}\boldsymbol{F}_{i}\right)  
 \end{equation} 
\\
\\
Tambi\'en consideramos los modelos l\'imites para $d=0$ y $d\rightarrow\infty$, respectivamente: Para $d=0$  obtenemos los modelos de efectos fijos y sin interceptos de bloques \\

\begin{equation}
Y_{ij}=\beta_{0}+\boldsymbol{f}(\mathrm{x}_{ij})^{\top}\boldsymbol{\beta}+\epsilon_{ij}
\end{equation}
\\
Obviamente, $\boldsymbol{M}_{d}$ tiende a $\boldsymbol{M}_{0}=\displaystyle\sum_{i=1}^{b}\boldsymbol{X}_{i}^{\top}\boldsymbol{X}_{i}$ para $d\rightarrow0$. Del mismo modo, $\boldsymbol{M}_{\boldsymbol{\beta},d}$ tiende a\\
\begin{equation}
\boldsymbol{M}_{\boldsymbol{\beta},0}=\displaystyle\sum_{i=1}^{b}\boldsymbol{F}_{i}^{\top}\boldsymbol{F}_{i}-\frac{1}{bm}\left( \displaystyle\sum_{i=1}^{b}\boldsymbol{F}_{i}^{\top}\boldsymbol{1}_{m}\right) \left( \displaystyle\sum_{i=1}^{b}\boldsymbol{1}_{m}^{\top}\boldsymbol{F}_{i}\right) 
\end{equation}
\\
\\
Para $d\rightarrow\infty$ introducimos el modelo de efectos fijos con bloques fijos\\
\begin{equation}
Y_{ij}=\mu_{i}+\boldsymbol{f}(\mathrm{x}_{ij})^{\top}\boldsymbol{\beta}+\epsilon_{ij};   \  (\mu_{i}=\gamma_{i}+\beta_{0})
\end{equation}
\\
Aqu\'i, el vector de par\'ametros $(\mu_{1},...\mu_{b},\beta_{1},...,\beta_{p})^{\top}$ tiene dimensi\'on $b+p$ y la matriz de información correspondiente tiene la forma\\

\begin{equation}
\boldsymbol{M}_{\infty}=\left(\begin{tabular}{ccc|c}
 & & & $\boldsymbol{1}_{m}^{\top}\boldsymbol{F}_{1}$ \\
 & $m\boldsymbol{I}_{b}$ & & $\vdots$ \\
 & & & $\boldsymbol{1}_{m}^{\top}\boldsymbol{F}_{b}$ \\
\hline
$\boldsymbol{F}_{1}^{\top}$ & $\cdots$ & $\boldsymbol{F}_{b}^{\top}\boldsymbol{1}_{m}$ & $\displaystyle\sum_{i=1}^{b}\boldsymbol{F}_{i}^{\top}\boldsymbol{F}_{i}$\\
\end{tabular}\right)
\end{equation}
\\
\\
Para $\boldsymbol{\beta}$ la matriz de informaci\'on parcial correspondiente se puede calcular\\ 
\begin{equation}
\boldsymbol{M}_{\boldsymbol{\beta},\infty}=\displaystyle\sum_{i=1}^{b}\boldsymbol{F}_{i}^{\top}\boldsymbol{F}_{i}-\frac{1}{m}\displaystyle\sum_{i=1}^{b}\boldsymbol{F}_{i}^{\top}\boldsymbol{1}_{m}\boldsymbol{1}_{m}^{\top}\boldsymbol{F}_{i}
\end{equation}
\\
De ahí se obtiene el siguiente resultado, que establece la matriz de informaci\'on parcial $\boldsymbol{M}_{\boldsymbol{\beta},d}$.\\
\\

$\mathbf{Lema 1.}$\\
\begin{equation}
\boldsymbol{M}_{\boldsymbol{\beta},d}=\frac{1}{1+md}\boldsymbol{M}_{\boldsymbol{\beta},0}+\frac{md}{1+md}\boldsymbol{M}_{\boldsymbol{\beta},\infty}
\end{equation}
\\
\textit{Tenga en cuenta que la matriz de informaci\'on parcial $\boldsymbol{M}_{\boldsymbol{\beta},d}$ tiende a $\boldsymbol{M}_{\boldsymbol{\beta},\infty}$ cuando $d$ tiende a  $\infty$.}\\
\\

\section{Aspectos del diseño}	
La calidad de los estimadores $\boldsymbol{\hat{\theta}}$ y $\boldsymbol{\hat{\beta}}$ depende de la configuraci\'on experimental $\mathrm{x}_{ij}$, $i=1,...,b$, $j=1,...,m$, a trav\'es de las matrices de informaci\'on  $\boldsymbol{M}_{d}$ y $\boldsymbol{M}_{\boldsymbol{\beta},d}$, respectivamente. El objetivo en el diseño experimental es elegir los puntos de una regi\'on diseño $\mathcal{X}$ con el fin de minimizar la covarianza $Cov(\boldsymbol{\hat{\theta}})$ o $Cov(\boldsymbol{\hat{\beta}})$ o partes de ella, lo cual es equivalente a maximizar las correspondientes matrices de información $\boldsymbol{M}_{d}$ o $\boldsymbol{M}_{\boldsymbol{\beta},d}$ respectivamente. Como esas matrices no est\'an completamente ordenadas, una optimizaci\'on uniforme no es posible, en general. Por lo tanto, algunos funcionales de valores reales que ponen \'enfasis en las propiedades particulares de los estimadores se optimizar\'an. El criterio de diseño m\'as usado es el $D-$criterio, que tiene como objetivo maximizar el determinante de la matriz de informaci\'on $\boldsymbol{M}_{d}$. Esto es equivalente a minimizar el volumen de un elipsoide de confianza para $\boldsymbol{\theta}$ bajo la suposici\'on de normalidad.\\

Si el inter\'es est\'a en los efectos $\boldsymbol{\beta}$ solamente, $D_{\boldsymbol{\beta}}-$optimalidad se define en t\'erminos de la determinante de la inversa $\boldsymbol{M}_{\boldsymbol{\beta},d}^{-1}$ de la correspondiente matriz de informaci\'on parcial. Como se ve a continuaci\'on,

\begin{equation}
\begin{aligned}
\nonumber
\det(\boldsymbol{M}_{d}) & =
\left|  \frac{1}{1+md}\left(\begin{tabular}{c | c}
$bm$ & $\displaystyle\sum_{i=1}^{b}\boldsymbol{1}_{m}^{T}\boldsymbol{F}_{i}$ \\
\hline
$\displaystyle\sum_{i=1}^{b}\boldsymbol{F}_{i}^{\top}\boldsymbol{1}_{m}$ & $(1+md)\displaystyle\sum_{i=1}^{b}\boldsymbol{F}_{i}^{\top}\boldsymbol{F}_{i}-d\displaystyle\sum_{i=1}^{b}\boldsymbol{F}_{i}^{\top}\boldsymbol{1}_{m}\boldsymbol{1}_{m}^{\top}\boldsymbol{F}_{i}$ \\
\end{tabular}\right)\right|
\end{aligned}
\end{equation}

$=\left( \frac{1}{1+md}\right)^{p+1}\left|bm\right||(1+md)\displaystyle\sum_{i=1}^{b}\boldsymbol{F}_{i}^{\top}\boldsymbol{F}_{i}-d\displaystyle\sum_{i=1}^{b}\boldsymbol{F}_{i}^{\top}\boldsymbol{1}_{m}\boldsymbol{1}_{m}^{\top}\boldsymbol{F}_{i}$

$$-\displaystyle\sum_{i=1}^{b}\boldsymbol{F}_{i}^{\top}\boldsymbol{1}_{m}(bm)^{-1}\displaystyle\sum_{i=1}^{b}\boldsymbol{1}_{m}^{T}\boldsymbol{F}_{i}|$$

$=\left( \frac{1}{1+md}\right)^{p+1}\left|bm\right||\displaystyle\sum_{i=1}^{b}\boldsymbol{F}_{i}^{\top}\boldsymbol{F}_{i}+md\displaystyle\sum_{i=1}^{b}\boldsymbol{F}_{i}^{\top}\boldsymbol{F}_{i}-d\displaystyle\sum_{i=1}^{b}\boldsymbol{F}_{i}^{\top}\boldsymbol{1}_{m}\boldsymbol{1}_{m}^{\top}\boldsymbol{F}_{i}$

$$-\frac{1}{bm}\displaystyle\sum_{i=1}^{b}\boldsymbol{F}_{i}^{\top}\boldsymbol{1}_{m}\displaystyle\sum_{i=1}^{b}\boldsymbol{1}_{m}^{T}\boldsymbol{F}_{i}|$$

$=\left( \frac{1}{1+md}\right)^{p+1}\left|bm\right||\displaystyle\sum_{i=1}^{b}\boldsymbol{F}_{i}^{\top}\boldsymbol{F}_{i}-\frac{1}{bm}\displaystyle\sum_{i=1}^{b}\boldsymbol{F}_{i}^{\top}\boldsymbol{1}_{m}\displaystyle\sum_{i=1}^{b}\boldsymbol{1}_{m}^{T}\boldsymbol{F}_{i}$

$$+md\left( \displaystyle\sum_{i=1}^{b}\boldsymbol{F}_{i}^{\top}\boldsymbol{F}_{i}-\frac{1}{m}\displaystyle\sum_{i=1}^{b}\boldsymbol{F}_{i}^{\top}\boldsymbol{1}_{m}\boldsymbol{1}_{m}^{\top}\boldsymbol{F}_{i}\right)|$$


$=\left( \frac{1}{1+md}\right)^{p+1}\left|bm\right|\left|\boldsymbol{M}_{\boldsymbol{\beta},0}+md\boldsymbol{M}_{\boldsymbol{\beta},\infty}\right|$\\

$=\left( \frac{1}{1+md}\right)^{p+1}\left|bm\right|\left|(1+md)\left(\frac{1}{1+md}\boldsymbol{M}_{\boldsymbol{\beta},0}+\frac{md}{1+md}\boldsymbol{M}_{\boldsymbol{\beta},\infty}\right)\right|$\\


$=\left( \frac{1}{1+md}\right)^{p+1}\left|bm\right|\left|(1+md)\boldsymbol{M}_{\boldsymbol{\beta},d}\right|$\\


$=
\left( \frac{1}{1+md}\right)^{p+1}\left|bm\right|(1+md)^{p}\left|\boldsymbol{M}_{\boldsymbol{\beta},d}\right|$\\

$=
\frac{bm}{1+md}\det\left( \boldsymbol{M}_{\boldsymbol{\beta},d}\right)$
\\

sujeta por la f\'ormula para el determinante de matrices particionadas. Por lo tanto, $D$ y $D_{\boldsymbol{\beta}}-$ optimalidad coinciden tambi\'en en modelos de interceptos aleatorios, un hecho bien conocido en el ajuste de efectos fijos.\\
\\

$\mathbf{Lema 2.}$ \textit{Un diseño $(\mathrm{x}_{ij})$ es $D-$\'optimo si y s\'olo si es $D_{\beta}$-\'optimo.}\\

Si tenemos en cuenta los diseños que son uniformes en todos los bloques, es decir, en que los par\'ametros experimentales son los mismos para cada bloque, $\mathrm{x}_{ij}\equiv \mathrm{x}_{j}$, , entonces la situaci\'on se simplifica radicalmente. En este caso las matrices de diseños individuales coinciden, $\boldsymbol{\mathbf{F}}_{i}=\boldsymbol{\mathbf{F}}_{1}$ y $\boldsymbol{\mathbf{X}}_{i}=\boldsymbol{\mathbf{X}}_{1}$, respectivamente, y $\boldsymbol{\mathbf{X}}_{1}$ tiene que ser de rango columna completa para permitir estimabilidad de $\boldsymbol{\theta}$. Adem\'as, $\boldsymbol{\hat{\theta}}=\frac{1}{b} \displaystyle\sum_{i=1}^b \boldsymbol{\hat{\theta}}_{i}$ se reduce a la media de los valores ajustados de forma individual para los par\'ametros.\\

La matriz de covarianza estandarizada $\boldsymbol{M}_{d}^{-1}$ se descompone de forma aditiva en la matriz correspondiente $\boldsymbol{M}_{0}^{-1}$ para el modelo de efectos fijos y sin intercepciones individuales y la variabilidad de la intersecci\'on aleatoria (v\'ease, por ejemplo, Entholzner y otros., (2005)). Para la matriz de informaci\'on reducida observamos\\

\begin{equation}
 \boldsymbol{M}_{\boldsymbol{\beta},0}=b\left(\boldsymbol{\mathbf{F}}_{1}^{\top}\boldsymbol{\mathbf{F}}_{1}-\frac{1}{m}\boldsymbol{\mathbf{F}}_{1}^{\top}\boldsymbol{1}_{m}\boldsymbol{1}_{m}^{\top}\boldsymbol{\mathbf{F}}_{1}\right)=\boldsymbol{\mathbf{M}}_{\boldsymbol{\beta},\infty}
\end{equation}  
\\

y, en consecuencia, por el Lema 1 $\boldsymbol{M}_{\boldsymbol{\beta},d}=\boldsymbol{M}_{\boldsymbol{\beta},0}$ es independiente de $d$. As\'i, el diseño $D-$\'optimo para el modelo de efectos fijos y sin intersecciones individuales es $D-$ y  $D_{\boldsymbol{\beta}}-$\'optimo para cada $d\geq0$ visto en el Lema 2.\\


\section*{Ejemplo de aplicación del modelo propuesto}

Consideremos el modelo de regresi\'on cuadr\'atico en dos variables sin interacciones\\

$
Y_{i} =\beta_{0} + \beta_{1}\mathrm{x}_{1i} + \beta_{2}\mathrm{x}_{2i} + \beta_{11}\mathrm{x}^{2}_{1i} + \beta_{22}\mathrm{x}^{2}_{2i} + \epsilon_{i};   \    (\mathrm{x}_{1i},\mathrm{x}_{2i})\in [-1,1]\times[-1,1].
$ 
\\

El diseño $\boldsymbol{\xi}$ el cual asigna iguales pesos $\frac{1}{9}$ a las cuatro esquinas $(\pm1,\pm1)$, a los cuatro puntos centrales de los lados $(0,\pm1)$; $(\pm1,0)$ y al punto central $(0,0)$ de la regi\'on experimental. Este diseño es $D$-\'optimo para este modelo. Si el diseño $\boldsymbol{\xi}$ es bloqueado como sigue\\

$\xi_{1}=
\begin{pmatrix}
(-1,0) & (0,1) & (1,-1) \\
1/3 & 1/3 & 1/3 \\
\end{pmatrix},$ \  $\xi_{2}=
\begin{pmatrix}
(-1,-1) & (0,0) & (1,1) \\
1/3 & 1/3 & 1/3 \\
\end{pmatrix},$ \\  $\xi_{3}=
\begin{pmatrix}
(-1,1) & (1,0) & (0,-1) \\
1/3 & 1/3 & 1/3 \\
\end{pmatrix}.$
\\\\

Entonces por el lema 2, \ $\boldsymbol{\xi}$ es $D$-\'optimal para el correspondiente modelo en la presencia de efectos de bloques con respuesta\\

$
Y_{ij} =\beta_{0} + \beta_{1}\mathrm{x}_{1ij} + \beta_{2}\mathrm{x}_{2ij} + \beta_{11}\mathrm{x}^{2}_{1ij} + \beta_{22}\mathrm{x}^{2}_{2ij} + \gamma_{i} + \epsilon_{ij},
$ 
\\

en la $j$-\'esima corrida sobre el bloque $i$, $(i=1,2,3; \ j=1,2,3)$ con pesos dados por $\boldsymbol{\xi}(i,(\mathrm{x}_{1ij},\mathrm{x}_{2ij}))=\frac{1}{3}\xi_{i}(\mathrm{x}_{1ij},\mathrm{x}_{2ij}).$ Adem\'as este diseño $D$-\'optimal por bloques no depende del cociente de varianza $d$.
